---
layout: page
title: Deep Learning Security Workshop
---

# Overview

Deep learning has made huge advances and impact in many
areas of computer science such as vision, speech, NLP, and
robotics. Many exciting research questions lie in the
intersection of security and deep learning.

**First**, how will these deep learning systems behave in the
presence of adversaries? Research has shown that many of the
state-of-the-art deep learning systems can be easily fooled by
adversarial examples. We will explore fundamental questions in
this area including what types of attacks are possible on deep
learning systems, why they exist, and how we can defend
against them.

**Second**, how can deep learning techniques help security
applications? We will explore this area and study example
security applications using deep learning techniques including
program binary analysis, password security analysis, malware
detection and fraud detection.

This year we will also have a [Research Forum](forum.md) on Dec 14. Submission deadline is on Nov 5, 2017.

For more information and future announcements in deep learning and security, [sign up on the mailing list](https://groups.google.com/d/forum/deep-learning-security).

# Co-chairs

<div class="instructors">
     <div class="instructor">
       <a href="https://people.eecs.berkeley.edu/~dawnsong/">
         <div class="instructorphoto"><img src="assets/people/dawnsong.jpg"/></div>
         <div>Dawn Song</div>
       </a>
     </div>
     <div class="instructor">
       <a href="http://www.comp.nus.edu.sg/~prateeks/">
         <div class="instructorphoto"><img src="http://www.cs.berkeley.edu/~prateeks/photo-2.jpg"/></div>
         <div>Prateek Saxena</div>
       </a>
     </div>
</div>

# Schedule

To be determined.

# Sponsors

![Sponsors](assets/logo/banner.png)

